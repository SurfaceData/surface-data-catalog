# HuggingFace Datasets

This subdirectory provides HuggingFace dataset libraries.

We manage this very carefully to automatically manage the datasets based on
what's stored in the database.  We list some key steps below during development
time.

## Usage

Using the datasets managed on HuggingFace require the following pattern:

```py
from datasets import load_dataset
load_dataset('SurfaceData/Catalog',
             lang_pair, # ex: 'en_ig'
             use_auth_token=your_hugging_face_auth_token,
             apikey=your_surface_catalog_api_key)
```

While the repos are set as private HuggingFace hub requires `use_auth_token`.
That can either be `true` if logged in via the command line tool or it can be
an API key with read access.

In all cases, we require the custom dataset arg `apikey` which is the apikey
generated by the data catalog.  This will be forwarded to the dataset download
request and be used for authentication.

## Management Steps

1.  Create the new dataset hub on HuggingFace
1.  Add the dataset hub as a remote: `git remote add -f dataset-newhubname https://path/to/hub`
1.  Create the subdirectory as a subtree: `git subtree add --prefix datasets/newhubname dataset-newhubname main`
1.  Make changes as needed and commit
1.  Push the subtree to HuggingFace: `git subtree push --prefix datasets/newhubname dataset-newhubname main`

We followed the [Atlassian Git
Subtree](https://www.atlassian.com/git/tutorials/git-subtree) docs to setup
these steps.  By following these steps we can manage each subdirectory as a hub
dataset and update the hub as needed.

Soon, we'll prepare a template that'll live in this repo which can be used as
the basis for every dataset generated and then setup some automation to
auto-create the repo, populate it, and then simplify pushing.

## Automation Steps

All steps require logging into Huggingface first:

```sh
huggingface-cli login
```

### Repo Creation and Setup

These must be done before creating the dataset files.

```sh
huggingface-cli repo create task_dataset --type dataset --organization organization
git remote add -f task_dataset https://path/to/hub`
git subtree add --prefix datasets/task_dataset task_dataset main
```

### Repo Population and Update

```sh
yarn rw exec generate_dataset_scripts --api_url=deployed_api_url
git commit -am "Creating dataset scripts"
git subtree push --prefix datasets/task_dataset task_dataset main`
```

### Updating with changes

```sh
git subtree pull --prefix datasets/task_dataset task_dataset main`
yarn rw exec generate_dataset_scripts --api_url=deployed_api_url
git commit -am "Updating dataset scripts"
git subtree push --prefix datasets/task_dataset task_dataset main`
```
